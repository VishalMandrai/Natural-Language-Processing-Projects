{
 "cells": [
  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apple Stock Sentiment Prediction Using News Headlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all relevant libraries...\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>Hughes' instant hit buoys Blues</td>\n",
       "      <td>Jack gets his skates on at ice-cold Alex</td>\n",
       "      <td>Chaos as Maracana builds up for United</td>\n",
       "      <td>Depleted Leicester prevail as Elliott spoils E...</td>\n",
       "      <td>Hungry Spurs sense rich pickings</td>\n",
       "      <td>Gunners so wide of an easy target</td>\n",
       "      <td>...</td>\n",
       "      <td>Flintoff injury piles on woe for England</td>\n",
       "      <td>Hunters threaten Jospin with new battle of the...</td>\n",
       "      <td>Kohl's successor drawn into scandal</td>\n",
       "      <td>The difference between men and women</td>\n",
       "      <td>Sara Denver, nurse turned solicitor</td>\n",
       "      <td>Diana's landmine crusade put Tories in a panic</td>\n",
       "      <td>Yeltsin's resignation caught opposition flat-f...</td>\n",
       "      <td>Russian roulette</td>\n",
       "      <td>Sold out</td>\n",
       "      <td>Recovering a title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>The best lake scene</td>\n",
       "      <td>Leader: German sleaze inquiry</td>\n",
       "      <td>Cheerio, boyo</td>\n",
       "      <td>The main recommendations</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>...</td>\n",
       "      <td>On the critical list</td>\n",
       "      <td>The timing of their lives</td>\n",
       "      <td>Dear doctor</td>\n",
       "      <td>Irish court halts IRA man's extradition to Nor...</td>\n",
       "      <td>Burundi peace initiative fades after rebels re...</td>\n",
       "      <td>PE points the way forward to the ECB</td>\n",
       "      <td>Campaigners keep up pressure on Nazi war crime...</td>\n",
       "      <td>Jane Ratcliffe</td>\n",
       "      <td>Yet more things you wouldn't know without the ...</td>\n",
       "      <td>Millennium bug fails to bite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>Coventry caught on counter by Flo</td>\n",
       "      <td>United's rivals on the road to Rio</td>\n",
       "      <td>Thatcher issues defence before trial by video</td>\n",
       "      <td>Police help Smith lay down the law at Everton</td>\n",
       "      <td>Tale of Trautmann bears two more retellings</td>\n",
       "      <td>England on the rack</td>\n",
       "      <td>Pakistan retaliate with call for video of Walsh</td>\n",
       "      <td>Cullinan continues his Cape monopoly</td>\n",
       "      <td>...</td>\n",
       "      <td>South Melbourne (Australia)</td>\n",
       "      <td>Necaxa (Mexico)</td>\n",
       "      <td>Real Madrid (Spain)</td>\n",
       "      <td>Raja Casablanca (Morocco)</td>\n",
       "      <td>Corinthians (Brazil)</td>\n",
       "      <td>Tony's pet project</td>\n",
       "      <td>Al Nassr (Saudi Arabia)</td>\n",
       "      <td>Ideal Holmes show</td>\n",
       "      <td>Pinochet leaves hospital after tests</td>\n",
       "      <td>Useful links</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2000-01-03      0  A 'hindrance to operations': extracts from the...   \n",
       "1  2000-01-04      0                                          Scorecard   \n",
       "2  2000-01-05      0                  Coventry caught on counter by Flo   \n",
       "\n",
       "                                 Top2  \\\n",
       "0                           Scorecard   \n",
       "1                 The best lake scene   \n",
       "2  United's rivals on the road to Rio   \n",
       "\n",
       "                                            Top3  \\\n",
       "0                Hughes' instant hit buoys Blues   \n",
       "1                  Leader: German sleaze inquiry   \n",
       "2  Thatcher issues defence before trial by video   \n",
       "\n",
       "                                            Top4  \\\n",
       "0       Jack gets his skates on at ice-cold Alex   \n",
       "1                                  Cheerio, boyo   \n",
       "2  Police help Smith lay down the law at Everton   \n",
       "\n",
       "                                          Top5  \\\n",
       "0       Chaos as Maracana builds up for United   \n",
       "1                     The main recommendations   \n",
       "2  Tale of Trautmann bears two more retellings   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  Depleted Leicester prevail as Elliott spoils E...   \n",
       "1                             Has Cubie killed fees?   \n",
       "2                                England on the rack   \n",
       "\n",
       "                                              Top7  \\\n",
       "0                 Hungry Spurs sense rich pickings   \n",
       "1                           Has Cubie killed fees?   \n",
       "2  Pakistan retaliate with call for video of Walsh   \n",
       "\n",
       "                                   Top8  ...  \\\n",
       "0     Gunners so wide of an easy target  ...   \n",
       "1                Has Cubie killed fees?  ...   \n",
       "2  Cullinan continues his Cape monopoly  ...   \n",
       "\n",
       "                                      Top16  \\\n",
       "0  Flintoff injury piles on woe for England   \n",
       "1                      On the critical list   \n",
       "2               South Melbourne (Australia)   \n",
       "\n",
       "                                               Top17  \\\n",
       "0  Hunters threaten Jospin with new battle of the...   \n",
       "1                          The timing of their lives   \n",
       "2                                    Necaxa (Mexico)   \n",
       "\n",
       "                                 Top18  \\\n",
       "0  Kohl's successor drawn into scandal   \n",
       "1                          Dear doctor   \n",
       "2                  Real Madrid (Spain)   \n",
       "\n",
       "                                               Top19  \\\n",
       "0               The difference between men and women   \n",
       "1  Irish court halts IRA man's extradition to Nor...   \n",
       "2                          Raja Casablanca (Morocco)   \n",
       "\n",
       "                                               Top20  \\\n",
       "0                Sara Denver, nurse turned solicitor   \n",
       "1  Burundi peace initiative fades after rebels re...   \n",
       "2                               Corinthians (Brazil)   \n",
       "\n",
       "                                            Top21  \\\n",
       "0  Diana's landmine crusade put Tories in a panic   \n",
       "1            PE points the way forward to the ECB   \n",
       "2                              Tony's pet project   \n",
       "\n",
       "                                               Top22              Top23  \\\n",
       "0  Yeltsin's resignation caught opposition flat-f...   Russian roulette   \n",
       "1  Campaigners keep up pressure on Nazi war crime...     Jane Ratcliffe   \n",
       "2                            Al Nassr (Saudi Arabia)  Ideal Holmes show   \n",
       "\n",
       "                                               Top24  \\\n",
       "0                                           Sold out   \n",
       "1  Yet more things you wouldn't know without the ...   \n",
       "2               Pinochet leaves hospital after tests   \n",
       "\n",
       "                          Top25  \n",
       "0            Recovering a title  \n",
       "1  Millennium bug fails to bite  \n",
       "2                  Useful links  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data.csv\" , encoding = 'ISO-8859-1')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Data:\n",
    "- **Label** : '1' means stock price will surge and '0' means stock price will drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indexing all headline columns for preprocessing.....\n",
    "data = df.iloc[: , 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting all 25 headlines into one processed paragragh...\n",
    "comb_headlines = []\n",
    "\n",
    "for entry in range(0 , df.shape[0]):\n",
    "    temp = data.iloc[entry , :]                               ## Indexing row....\n",
    "    temp = temp.replace('[^a-zA-Z]' , ' ' , regex = True)     ## Removing all characters other than alphabets with space....\n",
    "    temp = temp.str.lower()                                   ## Converting all aphabets to lower case....\n",
    "    temp = ' '.join(str(x) for x in temp.values)              ## Joining all columns to make 1 para...\n",
    "    comb_headlines.append(temp)                               ## Appending the para to empty list...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing all stopwords from all paragraphs.....\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(comb_headlines)):\n",
    "    para = comb_headlines[i]\n",
    "    para = para.split()\n",
    "    para = [lem.lemmatize(word) for word in para if word not in stopwords.words('english')]\n",
    "    para = \" \".join(para)\n",
    "    comb_headlines[i] = para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## processed data....\n",
    "df_pro = pd.DataFrame(data = comb_headlines , columns = ['Headlines'])\n",
    "df_pro['Targets'] = df['Label']\n",
    "df_pro['Date'] = df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the processed dataset: 4101\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in the processed dataset:\" , df_pro.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making train test split....\n",
    "train=df_pro[df_pro['Date']<'20150101']\n",
    "test=df_pro[df_pro['Date']>'20141231']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying Vectorization.....\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#implement TF-IDF\n",
    "Tfidf = TfidfVectorizer(ngram_range=(2,3))\n",
    "x_train = Tfidf.fit_transform(train['Headlines'])\n",
    "y_train = train['Targets']\n",
    "\n",
    "## Applying vectorization on training data using TF-IDF before Model Building......\n",
    "x_test = Tfidf.transform(test['Headlines'])\n",
    "y_test = test['Targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=200)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators = 200 , criterion='entropy')\n",
    "rf_clf.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Train Accuracy is : 84.39153439153439\n",
      "The Test Accuracy is : 84.39153439153439\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.73      0.82       186\n",
      "           1       0.79      0.95      0.86       192\n",
      "\n",
      "    accuracy                           0.84       378\n",
      "   macro avg       0.86      0.84      0.84       378\n",
      "weighted avg       0.86      0.84      0.84       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The Train Accuracy is :\" , rf_clf.score(x_test , y_test)*100)\n",
    "print(\"The Test Accuracy is :\" , metrics.accuracy_score(y_test , rf_clf.predict(x_test))*100)\n",
    "print(\"\\n\" , metrics.classification_report(y_test , rf_clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  136   50\n",
       "1    9  183"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CONFUSION MATRIX for Test Results....\n",
    "pd.DataFrame(metrics.confusion_matrix(y_test , rf_clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NV = MultinomialNB()\n",
    "NV.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Train Accuracy is : 100.0\n",
      "The Test Accuracy is : 85.18518518518519\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82       186\n",
      "           1       0.77      1.00      0.87       192\n",
      "\n",
      "    accuracy                           0.85       378\n",
      "   macro avg       0.89      0.85      0.85       378\n",
      "weighted avg       0.89      0.85      0.85       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The Train Accuracy is :\" , NV.score(x_train , y_train)*100)\n",
    "print(\"The Test Accuracy is :\" , metrics.accuracy_score(y_test , NV.predict(x_test))*100)\n",
    "print(\"\\n\" , metrics.classification_report(y_test , NV.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  130   56\n",
       "1    0  192"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CONFUSION MATRIX for Test Results....\n",
    "pd.DataFrame(metrics.confusion_matrix(y_test , NV.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "- **Random Forest Classifier Model:** Gave good test results, with F1-score of 82% and 86%.\n",
    "- **Naive Bayesian Model:** Proved to be the best fit for this problem. With slightly improved F1-Score of 82% and 87%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
